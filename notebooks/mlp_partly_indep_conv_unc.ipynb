{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Uncertainty estimation using ensembles of partly independent MLP models\n",
    "\n",
    "**Model description:**\n",
    "\n",
    "-- Network outputs two values in the final layer, corresponding to the predicted **mean** and **variance** by treating the observed value as a sample from a Gaussian distribution\n",
    "\n",
    "-- Ensemble members are trained on different bootstrap samples of the original training set; the mean and variance of a mixture are given by $$\\mu_{*}(\\mathbf{x})=M^{-1} \\sum_{m} \\mu_{\\theta_{m}}(\\mathbf{x}),$$  $$\\sigma_{*}^{2}(\\mathbf{x})=M^{-1} \\sum_{m}\\left(\\sigma_{\\theta_{m}}^{2}(\\mathbf{x})+\\mu_{\\theta_{m}}^{2}(\\mathbf{x})\\right)-\\mu_{*}^{2}(\\mathbf{x}),$$ respectively.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from astropy.io import fits\n",
    "import numpy.ma as ma\n",
    "from inverse_problem import SpectrumDataset, PregenSpectrumDataset, make_loader\n",
    "from inverse_problem.nn_inversion.models_mlp import MlpPartlyIndepNet\n",
    "from inverse_problem.nn_inversion.transforms import normalize_output\n",
    "from inverse_problem.nn_inversion.posthoc import compute_metrics, open_param_file, plot_params, plot_pred_vs_refer\n",
    "from inverse_problem.nn_inversion.transforms import transform_dist\n",
    "from inverse_problem.nn_inversion.posthoc import plot_hist_params_comparison\n",
    "from inverse_problem.nn_inversion.posthoc import plot_analysis_hist2d_unc\n",
    "from inverse_problem.nn_inversion.posthoc import plot_spectrum, plot_model_spectrum, read_spectrum_for_refer\n",
    "from inverse_problem.nn_inversion import mlp_transform_rescale, normalize_spectrum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define ensemble size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ensemble_size = 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = '../data/parameters_base_new.fits'\n",
    "transform = None\n",
    "sobj = SpectrumDataset(param_path=filename, source='database', transform=transform)\n",
    "sample = sobj[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "line_type = ['I','Q','U','V']\n",
    "line_arg = 1000 * (np.linspace(6302.0692255, 6303.2544205, 56)) - 6302.5\n",
    "fig, ax = plt.subplots(2,2, figsize = (10,5))\n",
    "for i in range(4):\n",
    "    ax[i//2][i%2].plot(line_arg, sample['X'][0][:,i]); ax[i//2][i%2].set_title(f'Spectral line {line_type[i]}')\n",
    "fig.set_tight_layout(tight = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare data for training\n",
    "\n",
    "Options:\n",
    "-- angle transformation\n",
    "-- log transformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = fits.open(filename)[0].data\n",
    "def params_masked_rows(pars_arr):\n",
    "    max_par_values = np.array([par_arr.max() for par_arr in pars_arr.T])\n",
    "    min_par_values = np.array([par_arr.min() for par_arr in pars_arr.T])\n",
    "    bool_arr = (min_par_values + 1e-3 < pars_arr) & (pars_arr < max_par_values - 1e-3)\n",
    "    return np.all(bool_arr, axis=1)\n",
    "\n",
    "\n",
    "def create_masked_array(pars_arr):\n",
    "    rows_mask = params_masked_rows(pars_arr)\n",
    "    array_mask = rows_mask[:, np.newaxis] | np.zeros_like(pars_arr, dtype=bool)\n",
    "    return ma.masked_array(pars_arr, mask=~array_mask)\n",
    "rows_mask_params = params_masked_rows(params)\n",
    "filtered_params = params[rows_mask_params, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device.type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factors, cont_scale = [1, 1000, 1000, 1000], 40000\n",
    "angle_transformation, logB = True, True\n",
    "\n",
    "transform_name = \"conv1d_transform_rescale\"\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 1 if 'cuda' in device.type else 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader, val_loader = make_loader(data_arr=filtered_params, transform_name=transform_name,\n",
    "                                       factors=factors, cont_scale=cont_scale,\n",
    "                                       logB=logB, angle_transformation=angle_transformation,\n",
    "                                       batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "sample_batch = next(iter(train_loader))\n",
    "\n",
    "print('Size of spectrum batch: ', sample_batch['X'][0].shape)\n",
    "print('Size of cont batch: ', sample_batch['X'][1].shape)\n",
    "print('Size of true params batch: ', sample_batch['Y'].shape)\n",
    "\n",
    "print(f'\\nNumber of batches for train: {len(train_loader)}, for validation: {len(val_loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create path for saving"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = 'conv_ens'\n",
    "current_time = str(datetime.now().strftime('%m-%d_%H-%M'))\n",
    "save_path = '../' + model_name + '_' + current_time + '/'\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define ensemble\n",
    "\n",
    "output_dim=22 for uncertainty estimation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble = [MlpPartlyIndepNet(input_dim=224, output_dim=22, hidden_dims=[200, 200, 200],\n",
    "                              activation='elu', batch_norm=True, dropout=0.05, number_readout_layers=2).to(device) for _ in range(ensemble_size)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizers = [torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99)) for model in ensemble]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mdn_cost(mu, sigma, y):\n",
    "    dist = torch.distributions.Normal(mu, sigma)\n",
    "    return torch.mean(-dist.log_prob(y))\n",
    "\n",
    "\n",
    "def fit_step(model, optimizer, dataloader, max_steps=None):\n",
    "    train_loss = 0.0\n",
    "    train_it = 0\n",
    "    if max_steps is None:\n",
    "        max_steps = float('inf')\n",
    "    total = min(max_steps, len(dataloader))\n",
    "\n",
    "    with tqdm(desc=\"batch\", total=total, position=0, leave=True) as pbar_outer:\n",
    "        for i, inputs in enumerate(dataloader):\n",
    "            if i == total:\n",
    "                break\n",
    "            x = [inputs['X'][0].to(device), inputs['X'][1].to(device)]\n",
    "            y = inputs['Y'].to(device)\n",
    "            outputs = model(x)\n",
    "            outputs_mean = outputs[:, :11]\n",
    "            outputs_sigma = torch.exp(outputs[:, 11:])\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            losses = [mdn_cost(outputs_mean[:, ind], outputs_sigma[:, ind], y[:, ind])\n",
    "                      for ind in range(11)]\n",
    "            loss = torch.stack(losses).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_it += 1\n",
    "            if train_it % 10 == 0:\n",
    "                pbar_outer.update(10)\n",
    "        return train_loss / train_it\n",
    "\n",
    "\n",
    "def eval_step(model, dataloader, max_steps = None):\n",
    "    if max_steps is None:\n",
    "        max_steps = float('inf')\n",
    "    total = min(max_steps,len(dataloader))\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_it = 0\n",
    "    for i, inputs in enumerate(dataloader):\n",
    "        if i==total:\n",
    "            break\n",
    "        x = [inputs['X'][0].to(device), inputs['X'][1].to(device)]\n",
    "        y = inputs['Y'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(x)\n",
    "            outputs_mean = outputs[:, :11]\n",
    "            outputs_sigma = torch.exp(outputs[:, 11:])\n",
    "            losses = [mdn_cost(outputs_mean[:, ind], outputs_sigma[:, ind], y[:, ind])\n",
    "                      for ind in range(11)]\n",
    "            loss = torch.stack(losses).msean()\n",
    "            val_loss += loss.item()\n",
    "            val_it += 1\n",
    "    return val_loss / val_it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, loss, path='../'):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss},\n",
    "        path + f'ep{epoch}.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|█████████▉| 31240/31243 [3:51:52<00:01,  2.25it/s]  \n",
      "batch:   0%|          | 0/31243 [00:00<?, ?it/s]461.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 001 train_loss: -0.1612 val_loss -1.1058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|█████████▉| 31240/31243 [3:29:15<00:01,  2.49it/s]  \n",
      "batch:   0%|          | 0/31243 [00:00<?, ?it/s]663.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 002 train_loss: -2.3502 val_loss -2.5064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|█████████▉| 31240/31243 [3:27:31<00:01,  2.51it/s]  \n",
      "epoch: 100%|██████████| 3/3 [11:15:37<00:00, 13512.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 003 train_loss: -2.5075 val_loss -2.5039\n",
      "CPU times: user 2d 6min 8s, sys: 11h 44min 16s, total: 2d 11h 50min 24s\n",
      "Wall time: 11h 15min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_train_steps = None\n",
    "max_val_steps = None\n",
    "best_valid_loss = float('inf')\n",
    "history = []\n",
    "loss_history = []\n",
    "log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} val_loss {v_loss:0.4f}\"\n",
    "n_epochs = 3\n",
    "path_to_save = save_path\n",
    "log_dir=path_to_save\n",
    "with tqdm(desc=\"epoch\", total = n_epochs, position=0, leave=True) as pbar_outer:\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = fit_step(train_loader, max_train_steps)\n",
    "        val_loss = eval_step(val_loader, max_val_steps)\n",
    "        history.append((train_loss, val_loss))\n",
    "        if val_loss < best_valid_loss:\n",
    "            best_valid_loss = val_loss\n",
    "            save_model(path_to_save, epoch, val_loss)\n",
    "        pbar_outer.update(1)\n",
    "        tqdm.write(log_template.format(ep=epoch + 1, t_loss=train_loss,\n",
    "                                               v_loss=val_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}